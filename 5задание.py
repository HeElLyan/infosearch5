# -*- coding: utf-8 -*-
"""5задание.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_CEIwqXkNdy1DI9ZWPuHEBNR8OHt1-K5
"""

from google.colab import drive
drive.mount('gdrive')

def get_tokens_from_request(input):

    all_words = input.split(' ')

    #finding unique
    unique_words = []
    for word in all_words:
        if word not in unique_words:
            unique_words.append(word)

    #sort unique words
    unique_words.sort()

    # print(unique_words)
    return unique_words

from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
import nltk
nltk.download('wordnet')
 
lemmatizer = WordNetLemmatizer()

def get_lemmas(tokens):
    words_lemmas = {}

    for token in tokens:
        key = lemmatizer.lemmatize(token, 'v')
        words_lemmas.setdefault(key, [])
        words_lemmas[key].append(token)

    return words_lemmas

# get request
text = input()

# convert request to lemmas
input_tokens = get_tokens_from_request(text)
input_lemmas = get_lemmas(tokens)

print(input_tokens)
print(input_lemmas)

album_urls_path = 'gdrive/My Drive/4курс/Инфопоиск/result/index.txt'

album_urls = []
with open(album_urls_path, 'r') as source:
    album_urls = source.readlines()

# # remove index 
# album_urls = []
# for album_url in res:
#     local_url = album_url.split(' ').pop(1)
#     album_urls.append(local_url)
# print(album_urls)

inverted_index_path = 'gdrive/My Drive/4курс/Инфопоиск/result/inverted_index.txt'

with open(inverted_index_path, 'r') as source:
    inverted_indexes = source.readlines()

inverted_indexes[0]

local_list = []

for inverted_index in inverted_indexes:
    # remove \n and split data to a list of strs
    inverted_index = inverted_index.split('\n').pop(0).split(' ')
    local_list.append(inverted_index)

inverted_indexes = local_list

print(input_lemmas)

song_path = 'gdrive/My Drive/4курс/Инфопоиск/result/выкачка' + str(inverted_indexes[1][1]) + '.txt'

with open(song_path, 'r') as source:
    res = source.readlines()

# split data to get a word by index
res = res[0]
res = res.split(' ')

# get lemma from file by the word
lemmas_path = 'gdrive/My Drive/4курс/Инфопоиск/result/lemmas.txt'
with open(lemmas_path, 'r') as source:
    default_lemmas = source.readlines()

if res[int(inverted_indexes[1][2])] == input_tokens[1]:
    print(res[inverted_indexes[1][2]])
    print(input_tokens[1])

print(res[int(inverted_indexes[1][2])])
print(input_tokens[1])
# # find urls with the same request words
# for input_token in input_tokens:
#     for token in 


# path = input_path + 'выкачка' + str(i + 1) + '.txt'

default_lemmas[0]

res = default_lemmas[23].rstrip().replace(":", "").split(" ")

res

keys = [default_lemmas[i].rstrip().split(":")[0] for i in range(len(default_lemmas))]
print(keys)

vals = []
for i in range(len(default_lemmas)):
    local_list = []
  
    default_lemma = default_lemmas[i].rstrip().replace(":", "").split(" ")

    for j in range(1, len(default_lemma)):
        local_res = default_lemma[j]
        # print(local_res)
        # print(type(local_list))
        local_list.append(local_res)

    vals.append(local_list)

print(vals)

dictionary = dict(zip(keys, zip(vals)))
print(dictionary)

# # print dictionary.keys()[dictionary.values().index(16)]  # Prints george
# print(list(dictionary.keys())[list(dictionary.values())])