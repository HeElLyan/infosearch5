# -*- coding: utf-8 -*-
"""5final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JbO_Ib-E-cWzFNkUKopdppgdPwAsezJb
"""

from google.colab import drive
drive.mount('gdrive')

from nltk.stem import WordNetLemmatizer
from nltk.corpus import wordnet
import nltk
nltk.download('wordnet')
 
lemmatizer = WordNetLemmatizer()

def get_lemmas(tokens):
    words_lemmas = {}

    for token in tokens:
        key = lemmatizer.lemmatize(token, 'v')
        words_lemmas.setdefault(key, [])
        words_lemmas[key].append(token)

    return words_lemmas

    
def get_tokens_from_request(input):

    all_words = input.split(' ')

    #finding unique
    unique_words = []
    for word in all_words:
        if word not in unique_words:
            unique_words.append(word)

    #sort unique words
    unique_words.sort()

    # print(unique_words)
    return unique_words

def get_inverted_indexes_without_lemmas():

    # get lemmas inverted indexes 
    tokens_lemmas_indexes_path = 'gdrive/My Drive/4курс/Инфопоиск/result/lemmas_inverted_indexes.txt'

    with open(tokens_lemmas_indexes_path) as source:
        lemmas_inverted_indexes = source.read()

    lemmas_inverted_indexes = lemmas_inverted_indexes.split('\n')
    del lemmas_inverted_indexes[-1]


    lemmas_inverted_indexes_without_lemmas = lemmas_inverted_indexes.copy()

    for i in range(len(lemmas_inverted_indexes_without_lemmas)):
        lemmas_inverted_indexes_without_lemmas[i] = lemmas_inverted_indexes_without_lemmas[i].strip(':').split('  ')
        lemmas_inverted_indexes_without_lemmas[i][0] = lemmas_inverted_indexes_without_lemmas[i][0].split(':')[0]

    return lemmas_inverted_indexes_without_lemmas


def get_files_indexes(input_lemmas_keys):

    lemmas_inverted_indexes_without_lemmas = get_inverted_indexes_without_lemmas()

    files_info = []

    for input_lemmas_key in input_lemmas_keys:
        for loc_lemma in lemmas_inverted_indexes_without_lemmas:
            if input_lemmas_key == loc_lemma[0]:
                files_info.append(loc_lemma[1])

    for i in range(len(files_info)):
        files_info[i] = files_info[i].split(' ')

    for i in range(len(files_info)):
        for j in range(len(files_info[i])):
          files_info[i][j] = int(files_info[i][j])

    files_indexes = []
    for i in range(len(files_info)):
        for j in range(len(files_info[i])):
            if j % 2 == 0:
                files_indexes.append(files_info[i][j])

    files_indexes = sorted(list(dict.fromkeys(files_indexes)))

    return files_indexes


def get_files_links(files_indexes):
    # get album urls
    album_urls_path = 'gdrive/My Drive/4курс/Инфопоиск/result/index.txt'

    with open(album_urls_path) as source:
        album_urls = source.read()

    album_urls = album_urls.split('\n')
    del album_urls[-1]

    for i in range(len(album_urls)):
        album_urls[i] = album_urls[i].split(' ')

    for i in range(len(album_urls)):
        album_urls[i][0] = int(float(album_urls[i][0]))

    # get links to files with the same lemmas from request
    file_links = []

    for file_index in files_indexes:
        for album_url in album_urls:
            if file_index == int(album_url[0]):
                file_links.append(album_url[1])

    return file_links

def get_files_tf_idf(files_indexes):

    lemmas_tf_idfs_files = []

    for file_index in files_indexes:
      
        with open(tf_idf_path + 'lemmas-tf-idf' + str(file_index) + '.txt') as source:
            loc_lemmas_tf_idfs = source.read()

        loc_lemmas_tf_idfs = loc_lemmas_tf_idfs.split('\n')
        del loc_lemmas_tf_idfs[-1]

        lemmas_tf_idfs_files.append(loc_lemmas_tf_idfs)


    for i in range(len(lemmas_tf_idfs_files)):
        for j in range(len(lemmas_tf_idfs_files[i])):
            lemmas_tf_idfs_files[i][j] = lemmas_tf_idfs_files[i][j].split('  ')
            lemmas_tf_idfs_files[i][j] = lemmas_tf_idfs_files[i][j][1]
            lemmas_tf_idfs_files[i][j] = lemmas_tf_idfs_files[i][j].split(' ')[1]
            lemmas_tf_idfs_files[i][j] = float(lemmas_tf_idfs_files[i][j])
    
    return lemmas_tf_idfs_files

import math

def get_files_length(lemmas_tf_idfs_files):

    files_lengths = []

    #count lengths of files
    for lemmas_tf_idfs_file in lemmas_tf_idfs_files:

        loc_count = 0

        for value in lemmas_tf_idfs_file:
          
            loc_count += value ** 2

        files_lengths.append(math.sqrt(loc_count))

    return files_lengths

tf_idf_path = 'gdrive/My Drive/4курс/Инфопоиск/result/tf_idf/'

def get_lemmas_idfs_and_lemmas():
  
    with open(tf_idf_path + 'lemmas-tf-idf1.txt') as source:
        test_lemmas_idfs = source.read()

    test_lemmas_idfs = test_lemmas_idfs.split('\n')
    del test_lemmas_idfs[-1]

    for i in range(len(test_lemmas_idfs)):
        test_lemmas_idfs[i] = test_lemmas_idfs[i].split('  ')
        test_lemmas_idfs[i][1] = test_lemmas_idfs[i][1].split(' ')
        test_lemmas_idfs[i][0] = test_lemmas_idfs[i][0].split(': ')

    lemmas_idfs = [float(test_lemmas_idfs[i][1][0]) for i in range(len(test_lemmas_idfs))]

    only_lemmas = [test_lemmas_idfs[i][0][0] for i in range(len(test_lemmas_idfs))]

    return lemmas_idfs, only_lemmas

def get_input_lemmas_keys_vals(text):
    # convert request to tokens and lemmas
    input_tokens = get_tokens_from_request(text)
    input_lemmas = get_lemmas(input_tokens)

    input_lemmas_keys = list(input_lemmas.keys())
    input_lemmas_vals = list(input_lemmas.items())
    
    for i in range(len(input_lemmas_vals)):
        input_lemmas_vals[i] = input_lemmas_vals[i][1]

    return input_lemmas_keys, input_lemmas_vals

def get_input_lemmas_tf_idf(input_lemmas_keys, input_lemmas_vals):

    N = len(input_lemmas_keys)

    lemmas_idfs, only_lemmas = get_lemmas_idfs_and_lemmas()

    tf_idf_input_lemma = []

    for k in range(len(only_lemmas)):

        loc_count = 0

        for i in range(len(input_lemmas_vals)):
                
            if input_lemmas_keys[i] == only_lemmas[k]:

                loc_count += len(input_lemmas_vals[i])

        # if loc_count != 0:
          
        #     print(loc_count)

        tf_idf_input_lemma.append((loc_count / N) * lemmas_idfs[k])

    return tf_idf_input_lemma

def get_input_length(tf_idf_input_lemma):
  
    input_length = 0

    for tf_idf in tf_idf_input_lemma:
        input_length += tf_idf ** 2

    input_length = math.sqrt(input_length)

    return input_length

def my_sort(sub_li):

    sub_li.sort(key = lambda x: x[1], reverse = True)

    return sub_li


def get_proper_files(file_links, lemmas_tf_idfs_files, tf_idf_input_lemma, files_lengths, input_length):

    a_b_input_files = []

    for i in range(len(lemmas_tf_idfs_files)):
        count = 0
        for j in range(len(lemmas_tf_idfs_files[i])):
            count += lemmas_tf_idfs_files[i][j] * tf_idf_input_lemma[j]

        a_b_input_files.append(count)

    cos_sims = []

    for i in range(len(a_b_input_files)):
        cos_sims.append(a_b_input_files[i] / (files_lengths[i] * input_length))

    cos_sims_files = [[file_links[i], cos_sims[i]]  for i in range(len(file_links))]

    cos_sims_files = my_sort(cos_sims_files)

    cos_sims_files = [cos_sims_files[i][0] for i in range(len(cos_sims_files))]

    return cos_sims_files

text = input()

text_keys, text_vals = get_input_lemmas_keys_vals(text)
text_tf_idf = get_input_lemmas_tf_idf(text_keys, text_vals)

text_length = get_input_length(text_tf_idf)

files_indexes = get_files_indexes(text_keys)
files_links = get_files_links(files_indexes)

tf_idfs_files = get_files_tf_idf(files_indexes)
files_lengths = get_files_length(tf_idfs_files)

get_proper_files(files_links, tf_idfs_files, text_tf_idf, files_lengths, text_length)